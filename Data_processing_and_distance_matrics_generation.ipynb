{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of the distance matrice and its euclidean space transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first part of the pipeline, where the data is preprocessed, distance matrice is generated and transformed into a coordinate matrice with a help of an MDS procedure, implemented in R. \n",
    "\n",
    "The data preprocessing includes labels (Y) and features (X) generation in a form of 1d and 2d numpy arrays respectively.\n",
    "\n",
    "The distance matrice is obtained from the performances of each of the feature subsets on the cross-validation data set. The intrasubset distances are obtained based on the feature_importance parameter of Decision Tree classifier, sklearn implementation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gmql as gl\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import numpy as np\n",
    "# matplotlib properties\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "matplotlib.rcParams['font.size'] = 22\n",
    "matplotlib.rcParams['xtick.labelsize'] = 22\n",
    "matplotlib.rcParams['ytick.labelsize'] = 22\n",
    "matplotlib.rcParams['axes.labelsize'] = 30\n",
    "matplotlib.rcParams['axes.titlesize'] = 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The file contains implementations of all the used functions with the desciptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_proc_dm_generation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rpy2 module allows on usage of R inside of python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "sma = importr('smacof')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of all the required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 100 #number of iterations for finding the most optimal subset of features. \n",
    "#the subset is then subtracted from the list of available features and the operation is repeated \n",
    "subset_size = 5 #number of features to be chosen\n",
    "top_k = 2000 # feature selectrion procedure, where top k features based on chi2 test are taken\n",
    "tads = False #set to True if you want to work with tads set of genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data, generating features and labels for training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tads == True:\n",
    "    path = \"/home/nanni/Projects/ML/TAD_Trento/all_tcga_only_TADs.tsv\"\n",
    "else:\n",
    "    path = \"/home/nanni/Data/TCGA/all_tcga.tsv\"\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = get_raw_data(path, top_k, tads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining subsets and their scores, building a distance matrice on its basis, applying MDS, checking the preservation of the nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_generator_wrapper_subsets(X_train, Y_train, num_iters, subset_size,top_k)\n",
    "scores, ranks, inds = subset_scores_load(num_iters, subset_size, top_k, tads)\n",
    "dist_final = get_distance_matrix(scores,inds,ranks,top_k)\n",
    "R_mds = np.array(sma.torgerson(dist_final, p=dist_final.shape[0]-1))\n",
    "pres = check_preservation_of_dims(R_mds.T, dist_final, subset_size)\n",
    "print(pres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving coordinates matrice to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(R_mds)\n",
    "temp_df.to_csv('./distance matrices/MDSes/test_dm_mds.csv',index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second part of the pipeline - DL setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto(device_count = {'CPU': 1}, intra_op_parallelism_threads=7, inter_op_parallelism_threads=1)\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "import keras as k\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from keras.layers import (Lambda, MaxPooling1D, Flatten,\n",
    "                          Dropout, Dense, Input)\n",
    "from keras.models import Model\n",
    "from keras.backend import floatx\n",
    "from phcnn.layers import PhyloConv1D, euclidean_distances\n",
    "from phcnn.build_train import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the results reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aba76a97f5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping MDS represenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDSmat = mds_reshape(R_mds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping X and Y to the suitable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_input_test = keras.utils.to_categorical(Y_test, num_classes=None)\n",
    "Y_input_train = keras.utils.to_categorical(Y_train, num_classes=None)\n",
    "\n",
    "X_test_inp = X_test.reshape(X_test.shape[0],X_test.shape[1],-1)\n",
    "X_train_inp = X_train.reshape(X_train.shape[0],X_train.shape[1],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and training the model. Validation loss is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_train_inp, Y_input_train, MDSmat, nb_filters, nb_neighbors)\n",
    "model_trained = train_model(model, X_train_inp, Y_input_train, batch_size, 7, 30, model_name, MDSmat, dense = False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.array(Y_input_test)\n",
    "for i in range(0,Y_pred.shape[0]):\n",
    "    Y_pred[i,:] = model.predict(x = [X_test_inp[[i],:,:]])#, MDSmat[1:2:,:,:,:]])\n",
    "\n",
    "Y_pred_1d = to_1d_labels(Y_pred)\n",
    "rep = classification_report(Y_test,Y_pred_1d)\n",
    "print(rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
